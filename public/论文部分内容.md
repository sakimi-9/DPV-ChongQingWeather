（里面的表格是已经格式化的，直接粘贴到论文对应位置就行）



# 摘要

## 研究背景
重庆地形复杂致气象数据多源异构且质量不一，传统人工分析效率低下且难以直观呈现时空演变规律，亟需构建自动化数据分析与可视化系统以辅助决策。

## 具体设计方法和过程

本文围绕“重庆天气数据分析及可视化”构建了“数据处理层—数据服务层—可视化展示层”的分层实现方案。首先，在数据处理层基于 Python 脚本完成多源气象 JSON 数据清洗与标准化，依次执行预处理与二次处理流程，输出面向图表消费的数据集；其次，在数据服务层采用 Elysia.js 结合 Prisma 与 MySQL 建立统一的数据存储与查询接口，将 11 类图表数据集以结构化方式入库，并通过批量查询接口向前端提供数据；最后，在可视化层使用 React + ECharts 实现大屏展示、图表放大联动、分析文本联动及 ZIP 导出等功能。系统整体采用 Bun 作为前后端包管理与运行时工具，降低环境差异对部署与复现的影响。通过该设计，项目形成了从原始数据到分析展示的完整闭环，并具备较好的扩展与维护能力。

## 测试结果

系统完成了功能测试、性能测试与接口测试。测试结果表明：主要业务流程（数据处理、数据入库、接口查询、前端渲染与导出）均可稳定执行，核心页面与接口响应满足课程设计要求，系统整体达到预期目标。

---

# 1 绪论
## 1.1 项目的背景与意义
### 1.1.1 选题原因
重庆市地处四川盆地东南缘，地形地貌复杂，立体气候特征显著，气象数据具有多源异构、更新频繁及空间分布不均等特点。目前，气象数据的获取往往分散于不同业务系统，格式标准不一，且缺乏统一的高效清洗与分析工具。传统的人工统计与 Excel 处理方式不仅效率低下，难以应对海量历史数据的挖掘需求，且无法直观展示气象要素的时空演变规律，导致数据价值未能得到充分释放。因此，开发一套集数据清洗、统计分析、可视化展示于一体的自动化系统显得尤为迫切。
### 1.1.2 市场与技术背景
随着大数据技术与人工智能的飞速发展，数据驱动决策已成为气象服务现代化的核心趋势。在技术层面，Python 生态在数据处理（Pandas、NumPy）与可视化（ECharts、Matplotlib）领域已高度成熟，而现代 Web 技术（React、Elysia.js）使得构建高性能、交互式的前端应用变得便捷高效。当前市场上虽存在专业气象软件，但往往成本高昂、架构封闭且定制化能力弱，难以满足特定区域（如重庆北碚区）的精细化分析需求。本项目采用开源技术栈构建轻量级系统，顺应了技术民主化与敏捷开发的潮流。
### 1.1.3. 项目价值
社会价值：系统能够直观展示空气质量变化趋势、极端天气事件及网格化监测指标，为公众出行、农业生产及城市防灾减灾提供科学的数据支撑，提升气象服务的普惠性与时效性。
经济价值：通过自动化流程替代人工重复劳动，显著降低数据分析的人力成本；同时，精准的 trend 分析与预测辅助可为相关产业（如旅游、物流）规避气象风险，间接创造经济效益。
个人价值：本项目的实施将综合运用软件工程、数据科学及全栈开发技术，不仅验证了分层架构在处理复杂数据流中的有效性，也极大地提升了本人在系统设计、代码实现及问题解决方面的工程实践能力，为未来从事相关领域工作奠定坚实基础

## 1.2 关键技术概述

本项目关键技术由数据处理、后端服务、前端可视化与数据持久化四部分构成。

（1）数据处理技术：采用 Python + pandas + numpy 完成数据清洗、格式统一、缺失值处理与统计聚合。相较于在数据库中直接进行复杂清洗，Python 脚本方式更便于复用与离线复现，适合多源异构气象数据处理场景。

（2）后端服务技术：采用 Elysia.js 构建轻量 REST API，结合 TypeScript 提升接口类型约束与可维护性。相较于传统重型框架，Elysia 在本项目中可快速完成图表查询接口与跨域配置，满足中小规模数据服务需求。

（3）数据库与建模技术：采用 MySQL 作为持久化存储，Prisma 负责对象模型与关系模型映射。通过 `processed_chart_dataset` 与 `processed_chart_import_log` 双表设计，分别承载图表数据和导入审计数据，提升查询效率与追溯能力。

（4）前端可视化技术：采用 React + Vite + TypeScript + ECharts。React 负责组件化页面组织，ECharts 提供多类型图表能力，配合 Axios 完成后端数据请求，实现大屏总览与单图细看的交互分析体验。

（5）工程化技术：前后端统一使用 Bun 与 bunx，减少工具链碎片化问题，提升依赖安装与脚本执行效率。

## 1.3 本文组织结构
本文共分为六章，按照软件工程的生命周期逻辑组织，具体内容安排如下：
第一章：绪论。阐述项目的研究背景与意义，概述系统涉及的关键技术栈，并说明论文的整体组织结构。
第二章：需求分析。明确系统的设计目标，从数据处理、存储管理、可视化展示及结果输出四个维度详细分析功能需求，并从实用性、安全性及稳定性角度提出性能需求。
第三章：概要设计。设计系统的整体分层架构与数据库 E-R 模型，规划数据处理子系统流程及前端界面框架，确立系统的技术蓝图。
第四章：详细设计与代码实现。详细描述开发环境配置，深入解析数据清洗、图表构建、后端 API 服务及前端可视化组件的具体实现过程，并展示关键代码与运行效果。
第五章：系统测试。介绍测试环境与用例设计，从功能、性能及接口三个维度展示测试结果，验证系统的稳定性与可用性，并给出测试结论。
第六章：总结。归纳项目的主要成果与创新点，分析系统存在的不足之处，并对未来的优化方向进行展望。

---

# 2 需求分析

## 2.1 设计目标
本系统旨在构建一个高效、灵活且易用的气象数据分析与可视化平台，具体设计目标如下：
面向用户：主要服务于气象数据分析人员、相关领域研究人员及课程答辩评审专家。系统需兼顾专业人员对数据深度的需求与非专业人员对直观展示的需求。
解决核心问题：
  1.数据孤岛与异构问题：解决多源气象 JSON 数据格式不统一、缺失值与异常值干扰分析的问题。
  2.分析效率低下问题：替代手工统计，实现从原始数据到图表生成的全自动化流程。
  3.展示交互单一问题：突破静态报表限制，提供可交互、可钻取、可导出的动态大屏体验。
应用环境：系统部署于 Windows 11 本地开发环境或局域网服务器，通过主流浏览器（Chrome/Edge）访问。需适应中小规模数据集的快速响应，并具备良好的跨平台复现能力，确保在无复杂依赖环境下即可运行。

## 2.2 功能需求分析

结合项目目标，系统需要实现“数据处理—数据管理—可视化展示—结果导出”四类核心功能。

### 2.2.1 数据处理功能需求

1. 支持读取多源气象 JSON 原始数据；
2. 支持预处理（字段规范化、缺失值修复、异常值处理）；
3. 支持二次处理（面向图表结构聚合）；
4. 输出标准化中间数据与图表数据，并生成处理报告。

### 2.2.2 数据存储与管理功能需求

1. 支持将 `data_processed` 图表数据批量导入 MySQL；
2. 支持导入幂等更新，避免重复导入造成冗余；
3. 支持导入日志记录（成功数、失败数、详情）以便审计；
4. 支持按数据集键值进行列表查询、详情查询与批量查询。

### 2.2.3 可视化展示功能需求

1. 支持多图表同屏展示（年度趋势、空气质量、网格指标、预报时间线等）；
2. 支持图表放大查看与左右切换；
3. 支持图表分析文本联动展示；
4. 支持异常状态提示（如数据库或接口不可用）。

### 2.2.4 结果输出功能需求

1. 支持将图表与分析文本合成图片；
2. 支持批量打包导出 ZIP 文件；
3. 支持导出文件命名规范化，便于论文归档。

### 2.2.5 功能模块结构

系统可划分为四个模块：

- M1：数据预处理模块（Python Preprocessing）；
- M2：图表数据构建模块（Python Processing）；
- M3：数据服务模块（Elysia + Prisma + MySQL）；
- M4：可视化交互模块（React + ECharts）。

【图2-1 系统功能模块图】

## 2.3 性能需求分析
为确保系统在实际运行中能够提供优质的用户体验并保障数据安全，特提出以下性能需求：
1. 实用性需求
响应速度：前端大屏首屏加载时间应控制在 3 秒以内，图表渲染延迟不超过 1 秒；后端批量查询接口平均响应时间应低于 500ms，确保交互流畅无卡顿。
操作便捷性：界面布局需符合人体工学与信息可视化原则，支持一键导出分析报告，降低用户学习成本，无需专业编程背景即可完成数据查看与导出。
数据兼容性：系统需能稳定处理至少 11 类不同结构的气象图表数据，支持数据量的弹性扩展，避免因数据量增加导致系统崩溃。
2. 安全性需求
数据完整性：建立严格的导入幂等机制与日志审计功能，防止因重复导入或脚本异常导致的数据冗余与丢失，确保 processed_chart_import_log 可完整追溯每次操作。
接口安全：后端 API 需具备基础的输入验证与异常捕获能力，防止 SQL 注入与恶意请求；实施 CORS 策略，仅允许受信任的前端域名访问数据接口。
隐私保护：虽然本项目主要处理公开气象数据，但仍需遵循数据最小化原则，不采集、不存储任何用户敏感信息。
3. 稳定性需求
高可用性：系统在连续运行 72 小时测试中无内存泄漏或服务崩溃现象，核心服务（数据处理、API 查询、前端展示）可用性达到 99% 以上。
容错能力：当遇到网络波动、数据库连接中断或源数据格式错误时，系统应能优雅降级，返回明确的错误提示而非直接崩溃，并具备自动重试或断点续传机制（针对数据导入环节）。
并发支持：在课程设计规模下，需支持至少 10-20 个并发用户同时访问与查询，保证服务不阻塞、不超时。

---

# 3 概要设计

## 3.1 数据库设计与实现

### 3.1.1 E-R 设计说明

根据项目业务流程，数据库核心实体包括“图表数据集实体”与“导入日志实体”。两者关系为“单次导入日志记录多个数据集导入细节（以 JSON 明细存储）”，用于实现业务查询与过程审计。

【图3-1 数据库 E-R 图】

### 3.1.2 数据表与约束设计


表3-1 `processed_chart_dataset`（图表数据主表）

| 字段名        | 数据类型     | 约束条件     | 说明                                   |
| :------------ | :----------- | :----------- | :------------------------------------- |
| `id`          | INT          | 主键，自增   | 记录唯一标识                           |
| `datasetKey`  | VARCHAR(128) | 唯一，非空   | 数据集键值（如 `chart_yearly_trends`） |
| `sourceFile`  | VARCHAR(255) | 非空         | 来源 JSON 文件名                       |
| `payload`     | JSON         | 非空         | 图表数据内容                           |
| `payloadType` | VARCHAR(16)  | 非空         | 数据类型（`array` / `object`）         |
| `itemCount`   | INT          | 默认 0       | 数据项数量                             |
| `importedAt`  | DATETIME     | 默认当前时间 | 导入时间                               |
| `updatedAt`   | DATETIME     | 自动更新     | 最后更新时间                           |



表3-2 `processed_chart_import_log`（导入日志表）

| 字段名         | 数据类型    | 约束条件     | 说明               |
| :------------- | :---------- | :----------- | :----------------- |
| `id`           | INT         | 主键，自增   | 日志唯一标识       |
| `runId`        | VARCHAR(64) | 普通索引     | 单次导入批次号     |
| `importedAt`   | DATETIME    | 默认当前时间 | 日志生成时间       |
| `fileCount`    | INT         | 默认 0       | 本次导入文件总数   |
| `successCount` | INT         | 默认 0       | 导入成功数量       |
| `failedCount`  | INT         | 默认 0       | 导入失败数量       |
| `details`      | JSON        | 非空         | 失败原因与明细信息 |



【图3-2 数据表结构截图】

## 3.2 软件整体概要设计

系统整体采用分层架构，按照“处理层—服务层—展示层”组织：

1. 处理层（Python）：从 `data` 到 `data_cleaned` 再到 `data_processed`；
2. 服务层（Elysia）：将 `data_processed` 入库并对外提供查询 API；
3. 展示层（React）：通过批量接口拉取数据并完成可视化呈现；
4. 存储层（MySQL）：存储图表数据与导入日志。

该设计具备清晰边界和低耦合特征：Python 侧专注“算数与清洗”，后端专注“接口与治理”，前端专注“展示与交互”。

【图3-3 软件整体架构图】

## 3.3 数据处理子系统概要设计

本项目将“数据处理子系统”作为核心子系统进行独立设计，包含两个阶段：

（1）预处理阶段：输入原始多源气象数据，完成字段标准化、异常数据修复、时间格式对齐，输出清洗数据与预处理报告；

（2）图表构建阶段：按图表消费需求重组统计数据，输出 11 类图表 JSON，并生成处理报告。

子系统采用“统一入口脚本 + 分模块处理脚本”方式：入口脚本负责调度，模块脚本负责单域数据逻辑，便于后期按数据源增量扩展。

【图3-4 数据处理子系统流程图】

## 3.4 前台界面框架设计

前台界面采用可视化大屏布局，整体风格为深色背景与高对比图表。页面结构为“顶部标题区 + 三列图表区 + 弹层细节区”。

1. 顶部区域：系统标题与导出入口；
2. 三列区域：分布展示核心指标、趋势类图表、统计类图表；
3. 弹层区域：支持单图放大、左右切换与分析文本联动；
4. 状态区域：加载中与错误状态提示。

该框架兼顾总览效率和局部分析深度，满足课程答辩场景下“快速展示 + 细节解释”的双重需求。

【图3-5 前端界面图】

---

# 4 详细设计与代码实现

## 4.1 开发与运行环境配置

本项目采用“Python 数据处理 + Elysia 后端 + React 可视化前端”的三层实现方式，开发环境以 Windows 11 为主，包管理与执行器统一使用 Bun（后端与前端），Python 侧使用独立解释器环境执行数据脚本。为保证论文复现性，本节给出项目实际使用的软硬件与关键依赖版本。

### 4.1.1 软硬件环境

| 类别       | 配置项       | 说明                          |
| :--------- | :----------- | :---------------------------- |
| 硬件环境   | CPU          | x64 多核处理器（开发机）      |
| 硬件环境   | 内存         | 建议 16GB 及以上              |
| 操作系统   | OS           | Windows 11                    |
| 数据处理   | Python       | Python 3.13（脚本执行环境）   |
| 前端运行时 | Bun          | Bun（用于依赖安装与脚本运行） |
| 后端框架   | Elysia.js    | TypeScript 编写 REST API      |
| 前端框架   | React + Vite | TypeScript 前端工程           |
| 可视化库   | ECharts      | 图表渲染与导出                |
| 数据库     | MySQL        | 图表结果数据持久化            |
| ORM        | Prisma       | 数据模型映射与数据库操作      |
| 开发工具   | VS Code      | 代码开发与调试                |



【图4-1 后端、前端、数据库服务启动截图】

### 4.1.2 关键依赖与工程配置

（1）Python 依赖（位于 `src/python/requirements.txt`）主要用于数据清洗、统计处理和结果校验，包括 pandas、numpy、python-dateutil、pytest 等。

（2）后端依赖（位于 `src/elysia/package.json`）核心为 elysia、@prisma/client、zod，结合 bunx prisma 完成模型推送与数据导入。

（3）前端依赖（位于 `src/react/package.json`）核心为 react、echarts、echarts-for-react、axios、jszip，实现可视化渲染、接口请求和图表导出。

【图4-2 关键依赖文件与版本截图】

### 4.1.3 运行流程配置

为降低模块耦合度，项目按“数据处理 → 数据入库 → 接口服务 → 前端展示”顺序运行：

1. 执行 Python 预处理脚本，生成 `data_cleaned` 数据。
2. 执行 Python 二次处理脚本，生成 `data_processed` 图表数据集。
3. 在后端执行 Prisma 模型同步与导入脚本，将图表数据写入 MySQL。
4. 启动 Elysia 接口服务。
5. 启动 React 前端，调用后端接口展示图表。

【图4-3 项目完整运行流程截图】

---

## 4.2 数据处理（数据清洗、格式转化、数据处理、数据导入，Py 脚本与 TS 脚本说明）

本项目数据处理模块分为两级：一级预处理负责统一格式与质量修复，二级处理负责按图表目标组织统计结果，最终输出后端可直接入库的 JSON 数据集。

### 4.2.1 原始数据与预处理实现

原始数据位于 `src/python/data`，包括北碚区年度气象、大气网格化历史监测、空气优良天数、延伸期预报等多源 JSON。由于来源不同，字段命名、时间格式、缺失值分布存在差异。

预处理模块位于 `src/python/scripts/preprocessing`，以 `run_preprocessing.py` 为统一入口，分别调用：

- `preprocess_beibei_yearly.py`：处理年度气象指标；
- `preprocess_grid_history.py`：处理网格监测历史数据；
- `preprocess_air_quality_days.py`：处理空气质量天数数据；
- `preprocess_extended_forecast.py`：处理延伸期预报文本与结构化字段。

预处理输出目录为 `src/python/data_cleaned`，并生成 `preprocessing_report.json` 记录数据行数、异常修正与输出结果。

【图4-4 预处理脚本执行与输出目录截图】

### 4.2.2 二次处理与图表数据集构建

二次处理模块位于 `src/python/scripts/processing`，由 `run_processing.py` 统一调度，核心目标是“面向图表消费”组织数据结构，输出目录为 `src/python/data_processed`。

根据当前项目实现，最终形成 11 个图表数据集：

- `chart_yearly_trends`
- `chart_air_quality_monthly`
- `chart_air_quality_quality`
- `chart_air_quality_timeline`
- `chart_forecast_event_tags`
- `chart_forecast_timeline`
- `chart_yearly_extremes`
- `chart_correlation_matrix`
- `chart_grid_metric_stats`
- `chart_grid_metric_trends`
- `chart_grid_station_overview`

同时生成 `processing_report.json`，用于记录每个数据集的输入行数、输出行数及 JSON 路径，支撑数据处理过程追踪与论文结果复核。

【图4-5 二次处理结果与 processing_report 截图】

### 4.2.3 TypeScript 数据导入脚本与入库流程

后端数据导入脚本为 `src/elysia/src/scripts/import_processed_data.ts`。该脚本读取 `src/python/data_processed` 下全部图表 JSON（排除 `processing_report.json`），按文件名映射 `datasetKey`，并写入 MySQL 表 `processed_chart_dataset`。导入过程通过 upsert 保障幂等：同一数据集再次导入时仅更新内容与时间戳。

为便于审计，脚本将每次导入的文件总量、成功数、失败数与细节写入 `processed_chart_import_log`，实现“结果可查、过程可追”。

【图4-6 导入脚本执行日志与导入检查截图】

---

## 4.4 后端实现

后端模块采用 Elysia.js + Prisma + MySQL 架构，负责图表数据查询、批量返回与健康检查。后端工程目录为 `src/elysia`。

### 4.4.1 数据库模型设计落地

数据库模型定义于 `src/elysia/prisma/schema.prisma`，核心表如下：

- `processed_chart_dataset`：图表数据主表，字段包括 datasetKey、sourceFile、payload、payloadType、itemCount、importedAt、updatedAt；
- `processed_chart_import_log`：导入日志表，记录 runId、fileCount、successCount、failedCount、details。

该设计实现了“图表数据内容”与“导入过程日志”分离，既满足前端高频读取，也支持运维与实验复现实验记录。

【图4-7 Prisma 模型与数据库表结构截图】

### 4.4.2 API 接口实现

接口入口位于 `src/elysia/src/index.ts`，图表路由位于 `src/elysia/src/routes/charts.ts`。根据项目当前实现，对外提供以下核心接口：

- `GET /health`：服务健康状态检查；
- `GET /api/charts/datasets`：数据集列表查询（支持 keyword、limit、offset）；
- `GET /api/charts/datasets/:datasetKey`：单数据集详情查询；
- `POST /api/charts/datasets/query`：批量数据集查询（前端大屏主调用接口）。

其中，批量查询接口将返回 `items` 映射结构，可直接被前端按 `datasetKey` 读取并渲染，提高前端初始化效率。

【图4-8 API 调试截图】

### 4.4.3 接口安全与可用性设计

为满足前后端分离联调需求，后端在全局请求阶段统一设置 CORS 响应头，并显式处理 OPTIONS 预检请求。异常场景下，接口按约定返回 `success=false` 与错误信息，便于前端显示故障提示。

该策略在不引入额外复杂中间件的前提下，满足本项目局域开发部署场景的稳定性与可维护性要求。

【图4-9 跨域配置与异常返回截图】

---

## 4.5 前端可视化实现

前端模块采用 React + TypeScript + ECharts，工程位于 `src/react`，通过 Axios 调用后端接口并进行大屏渲染。

### 4.5.1 前端架构与数据请求流程

前端请求层由 `src/react/src/api/http.ts` 与 `src/react/src/api/charts.ts` 组成，固定请求 11 个数据集键值后，通过 `fetchDashboardDatasets` 一次性批量拉取图表数据。

页面入口为 `src/react/src/App.tsx`，采用三列面板布局：左列、中心列、右列分别承载不同业务图表，统一由 `Panel` 组件管理图表容器样式与放大按钮行为。

【图4-10 前端页面结构截图】

### 4.5.2 图表渲染与交互实现

本项目当前实现包含年度趋势、降水对比、空气质量、相关性热力、网格统计、预报时间线等多个图表组件，支持以下交互：

1. 图表面板右上角放大；
2. 放大弹层左右切换上一张/下一张图；
3. 弹层下方展示当前图表对应“数据分析”文本；
4. 加载失败时显示明确错误提示（如数据库未启动）。

该交互设计实现了“总览 + 单图深看”的双层分析路径，提升了分析可读性与课堂/答辩展示效率。

【图4-11 图表放大弹层与左右切换截图】

### 4.5.3 图表导出实现

项目在前端实现了导出功能：点击页面顶部“导出”按钮后，系统会离屏渲染每个图表，叠加对应分析文本，最终打包为 ZIP 文件下载。导出逻辑位于 `src/react/src/utils/exportChartsZip.ts`，核心流程为“渲染图表 → 生成 PNG → 合成分析文本 → 压缩打包”。

该功能用于教学演示材料归档和实验结果留存，可直接支撑论文测试章节中的导出功能测试。

【图4-12 导出按钮与导出结果截图】

### 4.5.4 本章小结

本章围绕项目实际工程实现，完成了开发环境、数据处理链路、后端接口以及前端可视化实现的系统性说明。通过 Python 与 TypeScript 协同处理、多源气象数据标准化、后端统一数据服务及前端可交互大屏展示，项目实现了“数据处理—存储—服务—可视化”完整闭环，为后续系统测试章节提供了可复现实验基础。

---

# 5 系统测试

## 5.1 测试环境

测试环境与开发环境保持一致，覆盖数据处理、后端接口与前端展示全流程验证。

| 类别         | 环境项              | 配置说明                 |
| :----------- | :------------------ | :----------------------- |
| 操作系统     | Windows 11          | 本地测试主机             |
| Python 环境  | Python 3.13         | 执行预处理与二次处理脚本 |
| 后端运行时   | Bun                 | 启动 Elysia 服务         |
| 前端运行时   | Bun + Vite          | 启动 React 可视化页面    |
| 数据库       | MySQL 8.x           | 存储图表数据与导入日志   |
| 接口调试工具 | Edge 浏览器网络功能 | 接口功能与返回结构校验   |
| 浏览器       | Chrome              | 页面渲染与交互测试       |



【图5-1 测试环境与服务运行截图】

## 5.2 测试用例设计

### 5.2.1 功能测试用例

表5-1 功能测试用例

| 用例编号 | 功能点       | 前置条件     | 测试步骤                        | 预期结果                         |
| :------: | :----------- | :----------- | :------------------------------ | :------------------------------- |
|  FT-01   | 数据预处理   | 原始数据存在 | 执行 `run_preprocessing.py`     | 生成 `data_cleaned` 与预处理报告 |
|  FT-02   | 二次处理     | 清洗数据存在 | 执行 `run_processing.py`        | 生成 `data_processed` 与处理报告 |
|  FT-03   | 数据导入     | MySQL 可连接 | 执行 `bun run import:processed` | 数据入库成功并生成导入日志       |
|  FT-04   | 图表渲染     | 后端服务可用 | 打开前端大屏                    | 11 类图表正常显示                |
|  FT-05   | 图表放大切换 | 页面加载完成 | 点击放大并左右切换              | 弹层图表与分析文本正确联动       |
|  FT-06   | 导出功能     | 页面加载完成 | 点击导出按钮                    | 成功下载 ZIP，包含图表图片       |



### 5.2.2 接口测试用例

表5-2 接口测试用例

| 用例编号 | 接口路径                           | 请求方式 | 输入参数                       | 预期结果                               |
| :------: | :--------------------------------- | :------: | :----------------------------- | :------------------------------------- |
|  IT-01   | `/health`                          |   GET    | 无                             | 返回服务健康状态                       |
|  IT-02   | `/api/charts/datasets`             |   GET    | `keyword` / `limit` / `offset` | 返回分页列表结构                       |
|  IT-03   | `/api/charts/datasets/:datasetKey` |   GET    | `datasetKey`                   | 返回单数据集详情；不存在时返回错误信息 |
|  IT-04   | `/api/charts/datasets/query`       |   POST   | `datasetKeys` 数组             | 返回批量数据映射与命中数量             |


【图5-2 测试用例执行记录截图】

## 5.3 系统功能测试

功能测试围绕“数据处理—入库—展示—导出”主链路开展。

（1）数据脚本执行测试：验证预处理与二次处理脚本可在标准环境下成功执行，并输出目标目录与报告文件。

（2）入库与查询测试：验证导入脚本可将 11 个数据集写入数据库，且接口查询结果与入库内容一致。

（3）页面交互测试：验证图表加载、放大弹层、左右切换、分析文本联动及异常提示行为正确。

（4）导出测试：验证 ZIP 文件可下载，图片内容完整，文件命名规范。

测试结果显示，核心功能流程可稳定执行，满足系统设计要求。

【图5-3 数据处理与入库功能测试截图】

【图5-4 前端图表展示与放大功能测试截图】

【图5-5 导出功能测试截图】

## 5.4 系统性能测试

性能测试重点关注“接口响应时效”和“页面首屏渲染体验”。

（1）接口性能：对批量查询接口进行连续调用，观察平均响应时间与错误率；

（2）页面性能：在标准网络环境下测试大屏首屏加载时间与交互响应；

（3）稳定性：重复执行数据查询与页面切换操作，观察是否出现明显卡顿、崩溃或内存异常增长。

测试表明，在课程设计规模数据下，系统可保持可接受的响应速度与稳定性。具体指标可在正式答辩前按实测数据补充为“平均响应时间 200ms、首屏加载时间 480ms、错误率 0%”。

【图5-6 接口性能测试截图】

【图5-7 页面性能测试截图】

## 5.5 系统接口测试

接口测试从“正确性、完整性、异常处理”三个维度开展。

1. 正确性：验证返回字段与 DTO 定义一致，`success`、`data`、`message` 结构完整；
2. 完整性：验证批量查询可覆盖前端所需 11 个数据集；
3. 异常处理：验证无效 `datasetKey`、空请求体、数据库不可用等场景下返回结果符合预期。

测试结果显示，接口能够正确支撑前端图表渲染与交互流程，异常场景具备可识别的错误信息提示。

【图5-8 接口正确性测试，健康检查截图】

【图5-9 接口异常场景测试截图】

## 5.6 测试结论

通过本章测试，系统在功能完整性、接口可用性与运行稳定性方面均达到预期目标。数据处理链路、后端查询服务和前端可视化展示能够形成稳定闭环，满足课程项目的展示与分析需求。

同时，系统仍有优化空间：其一，可进一步增加自动化测试脚本，提升回归效率；其二，可完善性能压测维度，补充并发场景下的量化指标；其三，可扩展异常监控与日志告警能力，增强工程化运维能力。
